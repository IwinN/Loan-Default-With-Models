---
title: "CIND119Project"
author: "IwinN"
date: "March 22, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Data Preparation
2. Predictive Modeling/Classification
a. Classification using Decision Tree
b. Classification using Naive Bayes
c. Choose one classification algorithm, apply and describe it
d. Compare the results of the 3 techniques
3. Post-prediction Analysis
a. Apply cluster analysis / association rule mining on the results of the classification to
provide customized recommendations to the organization for its customers.
4. Conclusions and Recommendations
Describe your results in your project report for each of the above steps. These steps are further
explained in the sections below. The suggested tool for this project is Weka but you can use any other
tools as well

1. Creditability: The class attribute (qualitative)showing whether the credit rating is good or
bad.
2. Account Balance: Checking account status (1: < 0 DM, 2: 0<=...<200 DM, 2 > 200 DM, 4: No
checking account), where DM= Deutsche Mark (qualitative attribute).
3. Duration of Credit (month): Duration of credit in months (numerical)
4. Payment Status of Previous Credit: Credit history (qualitative) 0: no credits taken, 1: all
credits at this bank paid back duly, 2: existing credits paid back duly till now, 3: delay in
paying off in the past, 4: critical account.
5. Purpose: Qualitative attribute showing the purpose of the loan 
(0: New car, 1: Used car , 2:Furniture/Equipment, 3: Radio/Television, 4: Domestic Appliances , 5: Repairs ,6: Education ,7:
Vacation, 8: Retraining ,9: Business, 10: Others)
6. Credit Amount: Numerical value showing the credit amount
7. Value Savings/Stocks: Qualitative attribute showing average balance in savings and stocks 
(1 : <100 DM, 2: 100<= ... < 500 DM, 3 : 500<= ... < 1000 DM, 4 : =>1000 DM, 5: unknown/ no savings
account)
8. Length of current employment: Qualitative attribute showing length of employment 
(1 :unemployed, 2: < 1 year, 3: 1<=...<4 years, 4: 4<=...<7 years, 5:>=7years).
9. Instalment percent: Installment rate in percentage of disposable income (numerical)
10. Sex & Marital Status: Qualitative attribute showing gender and marital status 
(1: male :divorced/separated, 2: female : divorced/separated/married, 3 : male: single, 4: male :married/widowed, 5 : female :single)
11. Guarantors: (Qualitative) Guarantors and co-applicants: 
(1 : none, 2 : co-applicant, 3 :guarantor)
12. Duration in Current address: Qualitative value showing the duration in current address 
(1: <= 1year, 1<...<=2 years, 2<...<=3 years, 3:>4years)
13. Most valuable available asset: Qualitative attribute showing valuable assets 
(1 : real estate, 2 : savings agreement/ life insurance, 3 : car or other, 4 : unknown / no property)
14. Age (years): Numerical value showing age in years.
15. Concurrent Credits: Installment plans ( 1 : bank, 2 : stores, 3 : none )
16. Type of apartment: Type of housing ( 1 : rent, 2 : own, 3 : for free)
17. No of Credits at this Bank: Numerical value showing number of existing credits at the bank
18. Occupation: Job (Qualitative) 
(1 : unemployed/ unskilled - non-resident, 2 : unskilled - resident, 3 : skilled employee / official, 4 : management/ self-employed/highly qualified employee/ officer)
19. No of dependents: Numerical value showing number of dependents
20. Telephone: Qualitative attribute for telephone number (1: yes, 2: No)
21. Foreign Worker: Qualitative attribute showing whether the person is the foreign worker or not 
(1:yes , 2: no)
```{r}
# #Data Preparation
# Look at the attribute type; e.g., nominal, ordinal or quantitative.
# ??? Find max, min, mean and standard deviation of attributes.
# ??? Determine any outlier values (records) for each of the attributes or attributes under
# consideration (min, max, std. dev, scatter plots, box plots or others can be used).
# ??? Analyze the distribution of numeric attributes (normal or other). 
#Plot histograms for attributes of concern and analyze whether they have any influence on the class
# attribute.
# ??? Load the dataset in Weka and click on visualization tab. Which attributes seem to be
# correlated? Which attributes seem to be most linked to the class attribute?
# ??? Which attributes do you think can be eliminated or included in the analysis?
# ??? Determine whether the dataset has an imbalanced class distribution (same
# proportion of records of different types or not).
# ??? Determine whether you need to handle missing values or transform any attributes
# (e.g., by normalizing the attributes, discretizing numeric attributes to categorical
# attributes, etc.). Weka filters (on the main tab) can be used for this purpose.
# Describe your findings for data preparation in your report.

gcd <- read.csv("german_credit.csv", header=T, stringsAsFactors = F,na.strings=c("","NA"))
gcd$Creditability <- factor(ifelse(gcd$Creditability==1, 0, 1))
levels(gcd$Creditability) <- c('No', 'Yes')
str(gcd)
summary(gcd)
```

```{r}
boxplot.stats(gcd$Credit.Amount) 
# #to get the outliers, conf	
# the lower and upper extremes of the 'notch' (if(do.conf)). See the details.
```
```{r}
#cor(gcd)
#library(corrr)
gcd %>% correlate() %>% network_plot(min_cor=0.0001)
```
```{r}
library(psych)
pairs.panels(gcd, scale=FALSE)
```
```{r}
library(ggcorrplot)

ggcorrplot(cor(gcd), p.mat = cor_pmat(gcd), hc.order=TRUE, type='lower')
```
```{r}
#corrgcd<- round(cor(gcd),1)
ggcorrplot(corrgcd, method = "circle")
```

```{r}
sapply(gcd,sd)
```

```{r}
# To identify the outliers of the numeric attributes, the values of the values of the numeric
# attributes are normalized into the domain range of [0, 1] and they are plotted as boxplot to view the outlier values. The code and the result for this step are given as below.
normalization <- function(gcd,x)
{for(j in x)
{gcd[!(is.na(gcd[,j])),j]=
(gcd[!(is.na(gcd[,j])),j]-min(gcd[!(is.na(gcd[,j])),j]))/
(max(gcd[!(is.na(gcd[,j])),j])-min(gcd[!(is.na(gcd[,j])),j]))}
return(gcd)}

c <- c(3,6,9,12,14,17,19)
normdata <- normalization(gcd,c)
library(datasets)
library(ggplot2)
boxplot(normdata[,c], horizontal=TRUE)

```

```{r}
levels(as.factor(gcd[,1]))
```

```{r}
for (x in c(2,4,5,7,8,10,11,13,15,16,18)) print (levels(as.factor(gcd[,x])))
```

```{r}
require(cluster)
```
```{r}
#require(cluster)
distance=daisy(gcd[,-22],stand=TRUE,metric=c("gower"), type = list(interval=c(3,6,9,12,14,17,19),nominal=c(2,4,5,7,8,10,11,13,15,16,18),binary=c(1,20,21)))
require(DMwR)
outlierdata=outliers.ranking(distance,test.data=NULL,method="sizeDiff",clus = list(dist="euclidean",
alg = "hclust", meth="average"), power = 1, verb = F)
```



```{r}
boxplot(outlierdata$prob.outliers[outlierdata$rank.outliers])
n=quantile(outlierdata$rank.outliers)
n1=n[1]
n4=n[4]
filler=(outlierdata$rank.outlier > n4*1.3)
gcd_noout=gcd[!filler,]
nrow(gcd_noout)
```
```{r}
require(DMwR)
gcd_noout_noimp=knnImputation(gcd_noout, k = 5, scale = T, meth = "weighAvg",
distData = NULL)
nrow(gcd_noout_noimp)
```

```{r}
library(DMwR)
split<-sample(nrow(gcd_noout_noimp), round(nrow(gcd_noout_noimp)*0.8))
trainingdata=gcd_noout_noimp[split,]
testdata=gcd_noout_noimp[-split,]
```

```{r}
# gcd_noout_noimp_train=trainingdata
str(trainingdata)
# gcd_noout_noimp_train$Creditability <- factor(ifelse(gcd_noout_noimp_train$Creditability == 1,0,1))
# gcd_noout_noimp_train$Creditability
gcd_noout_noimp_train_smot <- SMOTE(Creditability ~ ., gcd_noout_noimp_train,k=5,perc.over = 500)
```

```{r}
library(cluster)
dist1=daisy(gcd_noout_noimp_train[,-22],stand=TRUE,metric=c("gower"), type =
list(interval=c(3,6,9,12,14,17,19), nominal=c(2,4,5,7,8,10,11,13,15,16,18),binary=c(20,1)))
dist2=daisy(gcd_noout_noimp_train_smot[,-22],stand=TRUE,metric=c("gower"), type =
list(interval=c(3,6,9,12,14,17,19), nominal=c(2,4,5,7,8,10,11,13,15,16,18),binary=c(20,1)))
loc1=cmdscale(dist1,k=2)
loc2=cmdscale(dist2,k=2)
x1=loc1[,1]
y1=loc1[,2]
x2=loc2[,1]
y2=loc2[,2]
plot(x1,y1,type="n")
text(x1,y1,labels=gcd_noout_noimp_train[,1], col=as.numeric(gcd_noout_noimp_train[,1])+4)
plot(x2,y2,type="n")
text(x2,y2,labels=gcd_noout_noimp_train_smot[,1],col=as.numeric(gcd_noout_noimp_train_smot[,1])+4)
```
```{r}
library(package="ellipse")
c= c(3,6,9,12,14,17,19)
plotcorr(cor(gcd_noout_noimp_train[,c]),col=cl<-c(7,6,3))
```
```{r}
c= c(2,4,5,7,8,10,11,13,15,16,18)
plotcorr(cor(gcd_noout_noimp_train[,c]),col=cl<-c(7,6,3))
```

```{r}
library(randomForest)
set.seed(454)
data.frame(gcd_noout_noimp_train)
randf<-randomForest(Creditability~ ., data=gcd_noout_noimp_train, ntree=700, importance=TRUE,proximity=TRUE)

importance(randf, type=1,scale=TRUE)
```

```{r}

svg(filename="D:\\DataAnalysisRyerson\\CIND119\\Final Project\\ProjectSubmission\\pics\\randf.svg")
varImpPlot(randf)
dev.off()
```
```{r}
varImpPlot(randf)
```
```{r}
varImpPlot(randf)
dev.print(png, "D:\\DataAnalysisRyerson\\CIND119\\Final Project\\ProjectSubmission\\pics\\randf.png")
```
```{r}
findopt=rfcv(gcd_noout_noimp_train[,-1],
gcd_noout_noimp_train[,1], cv.fold=10, scale="log", step=0.9)
opt <- which.max(findopt$error.cv)
plot( findopt$n.var, findopt$error.cv, type= "h", main = "Importance", xlab="Number of Features",ylab = "Classifier Error Rate")
axis(1, opt, paste("Threshold", opt, sep="\n"), col = "red", col.axis = "red")
```
```{r}
library(rpart)
c = c(5, 9, 12, 16, 18, 19, 22)
trdata=data.frame(gcd_noout_noimp_train[,-c])
trdata
tree=rpart(trdata$Creditability~.,data=trdata,method="class")
printcp(tree)
```
```{r}
plot(tree, uniform=TRUE,main="Classification Tree")
text(tree, use.n=TRUE, all=TRUE, cex=0.7)
```
```{r}
predicttest=data.frame(testdata)
pred=predict(tree,predicttest)
c=c(1)
table(predict(tree, testdata, type="class",na.action=na.pass), testdata[, c])
```

```{r}

```

```{r}
set.seed(1)
LogisticModel <- glm(Creditability ~ Account.Balance + Payment.Status.of.Previous.Credit + Purpose + Length.of.current.employment + Sex...Marital.Status, family = binomial, data = gcd)
LogisticModel
```

